{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aspect category classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_colwidth' , -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2206, 5), (649, 5))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_grp_df = pd.read_csv('../data/resturant_train_stratified_grouped.csv')\n",
    "test_grp_df  = pd.read_csv('../data/resturant_test_stratified_grouped.csv')\n",
    "train_grp_df.shape , test_grp_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aspects</th>\n",
       "      <th>polarities</th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "      <th>ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['service']</td>\n",
       "      <td>['positive']</td>\n",
       "      <td>Service is fast and friendly.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['anecdotes/miscellaneous']</td>\n",
       "      <td>['negative']</td>\n",
       "      <td>I HATE HATE HATE this place.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       aspects    polarities                           text  \\\n",
       "0  ['service']                  ['positive']  Service is fast and friendly.   \n",
       "1  ['anecdotes/miscellaneous']  ['negative']  I HATE HATE HATE this place.    \n",
       "\n",
       "   length  ind  \n",
       "0  1       0    \n",
       "1  1       0    "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_grp_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First step of Aspect Based Sentiment Analysis is to extract the hidden aspect categories in given text/review. We are using a supurvised method for this.  We will learn a LinearSVM on tf-idf vectors for this multi label classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast \n",
    "train_grp_df['aspects'] = train_grp_df['aspects'].apply(lambda x: ast.literal_eval(x))\n",
    "train_grp_df['polarities'] = train_grp_df['polarities'].apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "test_grp_df['aspects'] = test_grp_df['aspects'].apply(lambda x: ast.literal_eval(x))\n",
    "test_grp_df['polarities'] = test_grp_df['polarities'].apply(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aspects</th>\n",
       "      <th>polarities</th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "      <th>ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[service]</td>\n",
       "      <td>[positive]</td>\n",
       "      <td>Service is fast and friendly.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[anecdotes/miscellaneous]</td>\n",
       "      <td>[negative]</td>\n",
       "      <td>I HATE HATE HATE this place.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     aspects  polarities                           text  \\\n",
       "0  [service]                  [positive]  Service is fast and friendly.   \n",
       "1  [anecdotes/miscellaneous]  [negative]  I HATE HATE HATE this place.    \n",
       "\n",
       "   length  ind  \n",
       "0  1       0    \n",
       "1  1       0    "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_grp_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import codecs\n",
    "\n",
    "def parse_sentence(line):\n",
    "    lmtzr = WordNetLemmatizer()\n",
    "    stop = stopwords.words('english')\n",
    "    try:\n",
    "        text_token = CountVectorizer().build_tokenizer()(line.lower())\n",
    "        text_rmstop = [i for i in text_token if i not in stop]\n",
    "        text_stem = [lmtzr.lemmatize(w) for w in text_rmstop]\n",
    "        return text_stem\n",
    "    except:\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_grp_df['pro_text'] = train_grp_df['text'].apply(lambda x: parse_sentence(x))\n",
    "test_grp_df['pro_text'] = test_grp_df['text'].apply(lambda x: parse_sentence(x))\n",
    "\n",
    "train_grp_df['clean_text'] = train_grp_df['pro_text'].apply(lambda x: ' '.join(x))\n",
    "test_grp_df['clean_text'] = test_grp_df['pro_text'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess text by tokenizing and lemmatizing then create tf-idf vectors on processed text. Then we create a multi label classifier using Linear SVM to predict aspects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aspects</th>\n",
       "      <th>polarities</th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "      <th>ind</th>\n",
       "      <th>pro_text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[service]</td>\n",
       "      <td>[positive]</td>\n",
       "      <td>Service is fast and friendly.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[service, fast, friendly]</td>\n",
       "      <td>service fast friendly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[anecdotes/miscellaneous]</td>\n",
       "      <td>[negative]</td>\n",
       "      <td>I HATE HATE HATE this place.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[hate, hate, hate, place]</td>\n",
       "      <td>hate hate hate place</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     aspects  polarities                           text  \\\n",
       "0  [service]                  [positive]  Service is fast and friendly.   \n",
       "1  [anecdotes/miscellaneous]  [negative]  I HATE HATE HATE this place.    \n",
       "\n",
       "   length  ind                   pro_text             clean_text  \n",
       "0  1       0    [service, fast, friendly]  service fast friendly  \n",
       "1  1       0    [hate, hate, hate, place]  hate hate hate place   "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_grp_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer , TfidfVectorizer ,TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the multi-labels into arrays\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import pickle\n",
    "mlb = MultiLabelBinarizer()\n",
    "y_train = mlb.fit_transform(train_grp_df.aspects)\n",
    "y_test = mlb.fit_transform(test_grp_df.aspects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 1],\n",
       "       [0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/FRACTAL/swati.tiwari/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy 0.8665639445300463\n"
     ]
    }
   ],
   "source": [
    "text_clf_svm = Pipeline([('vect', CountVectorizer()),\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('clf-svm', LabelPowerset(\n",
    "                             SGDClassifier(loss='log', penalty='l2', l1_ratio = 0.4,\n",
    "                                           alpha=1e-4, max_iter=40, random_state=42 )))])\n",
    "_ = text_clf_svm.fit(train_grp_df['clean_text'] , y_train)\n",
    "predicted_svm = text_clf_svm.predict(test_grp_df['clean_text'])\n",
    "print('Test accuracy' , np.mean(predicted_svm == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function to tweak threshold and determine aspect prediction using that threshold\n",
    "\"\"\"\n",
    "\n",
    "def make_pred(row , thresh):\n",
    "    cols = mlb.classes_.tolist()\n",
    "    res_asp = []\n",
    "    for ele in cols:\n",
    "        if row[ele]>thresh:\n",
    "            res_asp.append(ele)\n",
    "\n",
    "    if len(res_asp)==0:\n",
    "        best_sr = cols[np.argmax(row[cols].tolist())]\n",
    "        res_asp.append(best_sr)\n",
    "        return res_asp\n",
    "    return res_asp\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prob_df = pd.DataFrame(text_clf_svm.predict_proba(test_grp_df['clean_text']).toarray() , columns = mlb.classes_ , index = test_grp_df.index)\n",
    "test_grp_df= pd.merge(test_grp_df, test_prob_df , left_index = True , right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_grp_df['aspects_pred'] =test_grp_df.apply(lambda x: make_pred(x ,0.5) , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>aspects</th>\n",
       "      <th>aspects_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our teenage kids love it, too.</td>\n",
       "      <td>[anecdotes/miscellaneous]</td>\n",
       "      <td>[anecdotes/miscellaneous]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I recommend to anyone who wants to dress up and impress the lady.</td>\n",
       "      <td>[anecdotes/miscellaneous]</td>\n",
       "      <td>[anecdotes/miscellaneous]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>He has visited Thailand and is quite expert on the cuisine.</td>\n",
       "      <td>[food]</td>\n",
       "      <td>[food]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We were seated outside and the waiter spilled red wine and hot tea on myself and my date.</td>\n",
       "      <td>[service]</td>\n",
       "      <td>[food]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The crust is thin, the ingredients are fresh and the staff is friendly.</td>\n",
       "      <td>[food, service]</td>\n",
       "      <td>[food]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                        text  \\\n",
       "0  Our teenage kids love it, too.                                                              \n",
       "1  I recommend to anyone who wants to dress up and impress the lady.                           \n",
       "2  He has visited Thailand and is quite expert on the cuisine.                                 \n",
       "3  We were seated outside and the waiter spilled red wine and hot tea on myself and my date.   \n",
       "4  The crust is thin, the ingredients are fresh and the staff is friendly.                     \n",
       "\n",
       "                     aspects               aspects_pred  \n",
       "0  [anecdotes/miscellaneous]  [anecdotes/miscellaneous]  \n",
       "1  [anecdotes/miscellaneous]  [anecdotes/miscellaneous]  \n",
       "2  [food]                     [food]                     \n",
       "3  [service]                  [food]                     \n",
       "4  [food, service]            [food]                     "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_grp_df[['text' , 'aspects' , 'aspects_pred']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC ROC 0.9265175034852803\n",
      "F1 score 0.6629534590547215\n",
      "Overall accuracy 0.8665639445300463\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score , confusion_matrix , accuracy_score , precision_score , recall_score , roc_auc_score\n",
    "print(\"AUC ROC\"  , roc_auc_score(y_test ,text_clf_svm.predict_proba(test_grp_df['clean_text']).toarray() ))#\n",
    "print(\"F1 score\",f1_score(y_test ,mlb.transform(test_grp_df.aspects_pred) , average='macro' ))\n",
    "print('Overall accuracy' , np.mean(predicted_svm == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for different aspect categories \n",
      "ambience 0.8936825885978429\n",
      "anecdotes/miscellaneous 0.8012326656394453\n",
      "food 0.847457627118644\n",
      "price 0.9198767334360555\n",
      "service 0.8828967642526965\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy for different aspect categories ')\n",
    "print(\"ambience\" ,   accuracy_score( y_test[: , 0] ,mlb.transform(test_grp_df.aspects_pred)[:,0] ))\n",
    "print(\"anecdotes/miscellaneous\" ,   accuracy_score( y_test[: , 1] ,mlb.transform(test_grp_df.aspects_pred)[:,1] ))\n",
    "print(\"food\" ,   accuracy_score( y_test[: , 2] ,mlb.transform(test_grp_df.aspects_pred)[:,2] ))\n",
    "print(\"price\" ,   accuracy_score( y_test[: , 3] ,mlb.transform(test_grp_df.aspects_pred)[:,3] ))\n",
    "print(\"service\" ,   accuracy_score( y_test[: , 4] ,mlb.transform(test_grp_df.aspects_pred)[:,4] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look for the accuracy of conflicting statements (changing sentiment in single review for different aspects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC ROC 0.9007480631574447\n",
      "F1 score 0.5800866845743291\n",
      "Overall accuracy 0.7533980582524272\n"
     ]
    }
   ],
   "source": [
    "test_grp_df2 = test_grp_df[test_grp_df['ind']==1]\n",
    "y_test_conf = mlb.fit_transform(test_grp_df2.aspects)\n",
    "\n",
    "print(\"F1 score\",f1_score(y_test_conf ,mlb.transform(test_grp_df2.aspects_pred) , average='macro' ))\n",
    "print('Overall accuracy' , np.mean(text_clf_svm.predict(test_grp_df2['clean_text']) == y_test_conf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for different aspect categories \n",
      "ambience 0.6796116504854369\n",
      "anecdotes/miscellaneous 0.7572815533980582\n",
      "food 0.8446601941747572\n",
      "price 0.8058252427184466\n",
      "service 0.7572815533980582\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy for different aspect categories ')\n",
    "print(\"ambience\" ,   accuracy_score( y_test_conf[: , 0] ,mlb.transform(test_grp_df2.aspects_pred)[:,0] ))\n",
    "print(\"anecdotes/miscellaneous\" ,   accuracy_score( y_test_conf[: , 1] ,mlb.transform(test_grp_df2.aspects_pred)[:,1] ))\n",
    "print(\"food\" ,   accuracy_score( y_test_conf[: , 2] ,mlb.transform(test_grp_df2.aspects_pred)[:,2] ))\n",
    "print(\"price\" ,   accuracy_score( y_test_conf[: , 3] ,mlb.transform(test_grp_df2.aspects_pred)[:,3] ))\n",
    "print(\"service\" ,   accuracy_score( y_test_conf[: , 4] ,mlb.transform(test_grp_df2.aspects_pred)[:,4] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overall accuracy for test data is around 86% and F1 score is 66% . We will try some LSTM + Word embedding based techniques to improve the performace of the multi label classification problem."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
